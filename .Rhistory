c(Country, City, AccentCity, Region, Latitude, Longitude, Population) Population > 500000)
worldcitiespop <- read.csv("worldcitiespop.txt")
### cities with a known population with more than 500000 inhabitants
C-620big <- subset(worldcitiespop, select =
c(Country, City, AccentCity, Region, Latitude, Longitude, Population) Population > 500000)
worldcitiespop <- read.csv("worldcitiespop.txt")
### cities with a known population with more than 500000 inhabitants
C620big <- subset(worldcitiespop, select =
c(Country, City, AccentCity, Region, Latitude, Longitude, Population) Population > 500000)
C620big <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > 500000)
View(`C620big`)
### cities with a known population with more than 330000 inhabitants
C620big <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > 330000)
worldcitiespop <- read.csv("worldcitiespop.txt")
### cities with a known population with more than 333000 inhabitants
C620big <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > 333000)
C620big <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > 333333)
View(`C620big`)
View(`C620big`)
View(worldcitiespop)
View(`C620big`)
install.packages("httr")
install.packages("dplyr")
install.packages("XML")
library(httr)
library(dplyr)
library(XML)
URL <- 'http://en.wikipedia.org/w/index.php?title=List_of_urban_areas_by_population&section=2'
# Get and parse all tables on the webpage
table <- readHTMLTable(URL)
UrbanCenters <- table [[2]]
UrbanCenters$City <- gsub("\\[.+?\\]","", UrbanCenters$City)
UrbanCenters$City <- gsub("\\(.+?\\)","", UrbanCenters$City)
UrbanCenters$City <- gsub("[[:digit:]]", "", UrbanCenters$City)
UrbanCenters$City <- gsub("[[:punct:]]", "", UrbanCenters$City)
View(UrbanCenters)
UrbanCenters["AccentCity"] <- UrbanCenters$City
try <- merge(c620big, UrbanCenters, by=c(AccentCity))
try <- merge(C620big, UrbanCenters, by=c(AccentCity))
try <- merge(C620big, UrbanCenters, by=c("AccentCity"))
View(try)
#############################
###building a city dataset###
#############################
worldcitiespop <- read.csv("worldcitiespop.txt")
### cities with a known population with more than 333000 inhabitants
C620big <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > 1000000)
install.packages("httr")
install.packages("dplyr")
install.packages("XML")
library(httr)
library(dplyr)
library(XML)
URL <- 'http://en.wikipedia.org/w/index.php?title=List_of_urban_areas_by_population&section=2'
# Get and parse all tables on the webpage
table <- readHTMLTable(URL)
UrbanCenters <- table [[2]]
UrbanCenters$City <- gsub("\\[.+?\\]","", UrbanCenters$City)
UrbanCenters$City <- gsub("\\(.+?\\)","", UrbanCenters$City)
UrbanCenters$City <- gsub("[[:digit:]]", "", UrbanCenters$City)
UrbanCenters$City <- gsub("[[:punct:]]", "", UrbanCenters$City)
UrbanCenters["AccentCity"] <- UrbanCenters$City
try <- merge(C620big, UrbanCenters, by=c("AccentCity"))
install.packages("httr")
install.packages("dplyr")
worldcitiespop <- read.csv("worldcitiespop.txt")
### cities with a known population with more than 333000 inhabitants
C620big <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > 1000000)
library(httr)
library(dplyr)
library(XML)
URL <- 'http://en.wikipedia.org/w/index.php?title=List_of_urban_areas_by_population&section=2'
# Get and parse all tables on the webpage
table <- readHTMLTable(URL)
UrbanCenters <- table [[2]]
UrbanCenters$City <- gsub("\\[.+?\\]","", UrbanCenters$City)
UrbanCenters$City <- gsub("\\(.+?\\)","", UrbanCenters$City)
UrbanCenters$City <- gsub("[[:digit:]]", "", UrbanCenters$City)
UrbanCenters$City <- gsub("[[:punct:]]", "", UrbanCenters$City)
UrbanCenters["AccentCity"] <- UrbanCenters$City
try <- merge(C620big, UrbanCenters, by=c("AccentCity"))
View(try)
### cities with a known population with more than 333000 inhabitants
C620big <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > 10000)
library(httr)
library(dplyr)
library(XML)
URL <- 'http://en.wikipedia.org/w/index.php?title=List_of_urban_areas_by_population&section=2'
# Get and parse all tables on the webpage
table <- readHTMLTable(URL)
UrbanCenters <- table [[2]]
UrbanCenters$City <- gsub("\\[.+?\\]","", UrbanCenters$City)
UrbanCenters$City <- gsub("\\(.+?\\)","", UrbanCenters$City)
UrbanCenters$City <- gsub("[[:digit:]]", "", UrbanCenters$City)
UrbanCenters$City <- gsub("[[:punct:]]", "", UrbanCenters$City)
UrbanCenters["AccentCity"] <- UrbanCenters$City
try <- merge(C620big, UrbanCenters, by=c("AccentCity"))
View(try)
intsall.package(maps)
intsall.packages(maps)
intsall.packages("maps")
install.packages("maps")
library(maps)
map("state", proj="bonne", param=45, fill=TRUE, plot=FALSE)
area.map(m, "North Dakota")
m<- map("state", proj="bonne", param=45, fill=TRUE, plot=FALSE)
area.map(m, "North Dakota")
m<- map("state", proj="bonne", param=45, fill=TRUE, plot=FALSE)
area.map(m, "North Dakota")
map(usa)
map('usa')
map()
data(world.cities)
View(world.cities)
m <- subset(world.cities, capital = "1")
View(m)
m <- subset(world.cities, select = c(name, capital = "1")
)
View(world.cities)
m <- subset(world.cities, select = c(name, capital = 1))
m <- subset(world.cities, select = c(name, capital = 1))
View(m)
m <- subset(world.cities, select = c(name, capital < 0))
View(m)
m <- subset(world.cities, select = c(name, capital == 0))
m <- subset(world.cities, select = c(name, capital == 1))
View(m)
m <- subset(world.cities, select = name), capital == 1)
m <- subset(world.cities, select = name, capital == 1)
View(m)
View(m)
View(m)
m <- subset(world.cities, select = name, capital == 2)
View(m)
m <- subset(world.cities, select = name, capital == 3)
View(m)
m <- subset(world.cities, select = name, capital == 1)
View(m)
setwd("C:/Users/Lokus/Dropbox/UrbanTerror")
#Loading R packages using @stevenworthington's ipak.R gist from https://gist.github.com/stevenworthington/3178163.
# ipak function: install and load multiple R packages.
# check to see if packages are installed. Install them if they are not, then load them into the R session.
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
# usage
packages <- c("foreign", "car", "RCurl", "ggplot2", "WDI", "httr", "iterators", "dplyr", "plyr",
"XML", "maps", "ggmap", "Imap", "geosphere", "maptools", "rgeos", "foreach")
ipak(packages)
rm(packages)
rm(ipak)
########################################################################################
########################################################################################
############################   GATHERING  DATA    ######################################
########################################################################################
########################################################################################
############################################
###### The Global Terrorism Database  ######
############################################
############################################
#Load the Global Terrorism Database (GTD). It is open souce and can be downloaded after registration at
# http://www.start.umd.edu/gtd/contact/
rawGTD <- read.csv("Terror Data/globalterrorismdb_0814dist.csv", header=TRUE)
#The (GTD) contains over a 120k observations on more than 120 variables. We don't need them all.
#We therefore filter the database to make it fit our needs, erasing over a 100 variables.
#We only want to look at successfull terror attacks and include basic data on time, location and target.
GTD <- subset(rawGTD, select = c(eventid, iyear, imonth, iday, country, country_txt, region, provstate, region_txt, city, attacktype1, targtype1, targsubtype1,
weaptype1, weapsubtype1, propextent, nkill, nwound),
iyear >= 1970 & success == 1, na.strings = c("", " "))
rm(rawGTD)
#Next we order the GTD)
GTD <- GTD[order (GTD$country_txt, GTD$iyear, GTD$imonth, GTD$iday, GTD$city), ]
############################################
#We introduce our first scale: "Targets Urbanity Potential Scale (TUPscale)"
GTD["TUPscale"] <- GTD$targsubtype1
GTD$TUPscale <- recode(GTD$TUPscale, "40:42 = 9; 9 = 0; 27:35 = 0; 37:39 = 0; 65 = 0; 72 = 0; 1 = 2; 4:5 = 2; 10 = 2;
12 = 2; 53:56 = 2; 58:59 = 2; 61:62 = 2; 82 = 2; 95:96 = 2;6 = 9; 13 = 9; 104:108 = 9;
51:52 = 9; 57 = 9; 60 = 9; 63:64 = 9; 73 = 9; 80:81 = 9; 88:92 = 9; 98 = 9; 2 = 7; 3 = 7;
7:8 = 7; 44 = 7; 48:50 = 7; 67:71 = 7; 74:79 = 7; 83:87 = 7; 97 = 7; 99 = 7; 14:26 = 9;
100:103 = 9; 111 = 9; 109 = 9; 110 = 9; 36 = 9; 43 = 9; 45:47 = 9; 66 = 9; 93:94 = 9;
11 = 9", as.numeric.result=TRUE)
# 0= Rural & Military; 2= Government & Police; 3= Potentilly Urban Workplace; #7= Potentilly Urban Infrastructure;
# 9= Potentilly Expression of Urban Core Life
############################################
# We introduce our second scale: "Extent of Property Damage (PROPscale)" and write it back into the GTD
GTD["PROPscale"] <- GTD$propextent
GTD$PROPscale <- as.numeric(GTD$PROPscale)
#Bring the values to the $ values coded in the originally coded categories.
GTD$PROPscale <- recode(GTD$PROPscale, "1=1000000000; 2=1000000; 3=1000; 4=0; NA=NA")
############################################
# We introduce our third scale: "Extent of Human Damage (HUMscale)" which adds wounded and killed /and write it back into the GTD
GTD["HUMscale"] <- GTD$nkill+GTD$nwound
GTD$HUMscale <- as.numeric(GTD$HUMscale)
# run our cleaning code for bringing the GDT country code to World Bank levels
source('SmallScripts/CountryCleaning.R')
View(GTD)
unique(GTD$country_txt)
sum(is.na(GTD&city))
sum(is.na(GTD$city))
sum(GTD$city == "unknown"))
sum(GTD$city == "unknown")
sum(GTD$city == "na")
sum(GTD$city == "(blank)")
WDIData <- WDI(indicator=c('EN.URB.LCTY.UR.ZS',
'EN.URB.MCTY',
'EN.URB.MCTY.TL.ZS',
'SP.URB.GROW',
'SP.URB.TOTL',
'SP.URB.TOTL.IN.ZS',
'EN.POP.DNST',
'EN.RUR.DNST',
'SP.RUR.TOTL',
'SP.RUR.TOTL.ZG',
'SP.RUR.TOTL.ZS'),
country="all", start=1970, end=2013, extra=FALSE,
)
WDIData <- WDIData[order(WDIData$country, WDIData$year), ]
###########################################
# WORLD CITY DATASET 1/2 (worldcities2013)
# here: http://download.maxmind.com/download/worldcities/worldcitiespop.txt.gz and transformed into CSV
worldcities2013 <- read.csv("City Data/worldcitiespop.csv")
# introduce Tehran as it was missing in the original dataset
worldcities2013 <- rbind(worldcities2013, data.frame(X=0,Country="ir", City="tehran", AccentCity="Tehran",
Region= 1, Latitude=35.67, Longitude=51.43,Population=7160094))
# introduce Akkaraipattu as it was missing in the original dataset
worldcities2013 <- rbind(worldcities2013, data.frame(X=0,Country="lk", City="Akkaraipattu", AccentCity="Akkaraipattu",
Region= 31, Latitude=7.227862, Longitude=81.850551,Population=35000))
# sorting by population
worldcities2013 <- worldcities2013[order(-worldcities2013$Population, na.last=TRUE) , ]
# replace 2digit coountry names by the names used in the secon city dataset
source('SmallScripts/2digit2ctry.R')
worldcities2013$City <- gsub(" ", "", worldcities2013$City)
worldcities2013$City <- tolower(worldcities2013$City)
##########################################
# WORLD CITY DATASET 2/2 (world.cities2009)
### list the world capital cities
data(world.cities)
world.cities$name <- tolower(world.cities$name)
world.cities2009 <- world.cities[order(-world.cities$pop, na.last=TRUE) , ]
rm(world.cities)
#The dataframe wrongly lists dehli as not being the capital of india, plus had a typo in seoul, which both we recode.
world.cities2009$capital[world.cities2009$name == "delhi" & world.cities2009$country.etc == "India"] <- "1"
world.cities2009$name[world.cities2009$name == "soul" & world.cities2009$country.etc == "Korea South"] <- "seoul"
world.cities2009$name[WC.UC.dist$name == "bombay" &  WC.UC.dist$country  == "India"] <- "mumbai"
# remane some countries so they match the first city dataset better
world.cities2009$country.etc[world.cities2009$country.etc == "Russia"] <- "Russian Federation"
world.cities2009$country.etc[world.cities2009$country.etc == "UK"] <- "United Kingdom"
world.cities2009$country.etc[world.cities2009$country.etc == "USA"] <- "United States of America"
world.cities2009$country.etc[world.cities2009$country.etc == "Korea North"] <- "Korea, Democratic People's Republic of"
world.cities2009$country.etc[world.cities2009$country.etc == "Korea South"] <- "Korea, Republic of"
world.cities2009$country.etc[world.cities2009$country.etc == "Sicily"] <- "Italy"
world.cities2009$country.etc[world.cities2009$country.etc == "East Timor"] <- "Timor-Leste"
world.cities2009$country.etc[world.cities2009$country.etc == "Madeira"] <- "Portugal"
world.cities2009$country.etc[world.cities2009$country.etc == "Madiera"] <- "Portugal"
##############################################################################################
# merge the two sets: cities 2013 and cities 2009 to world.cities
#some preliminary cleaning before merging
world.cities2009$name <- gsub(" ", "", world.cities2009$name)
world.cities2009$name <- tolower(world.cities2009$name)
world.cities2009$country.etc<-gsub(" ", "",world.cities2009$country.etc, ignore.case=TRUE)
world.cities2009$country.etc<-gsub("\\,", "",world.cities2009$country.etc, ignore.case=TRUE)
world.cities2009$country.etc <- tolower(world.cities2009$country.etc)
worldcities2013$Country <- tolower(worldcities2013$Country)
# subsets and renaming so the two datasets match in their columns
worldcities2013 <- subset(worldcities2013, select =c("City", "Country", "Population", "Latitude", "Longitude", "Region"))
colnames(worldcities2013)[1] <- "name"
colnames(worldcities2013)[2] <- "country.etc"
colnames(worldcities2013)[3] <- "pop"
colnames(worldcities2013)[4] <- "lat"
colnames(worldcities2013)[5] <- "long"
#create a column to merge over: countrycity
world.cities2009$merge <- paste(world.cities2009$country.etc, world.cities2009$name, sep="")
worldcities2013$merge <- paste(worldcities2013$country.etc, worldcities2013$name, sep="")
#merge to new set: "world.cities"
world.cities <- merge(world.cities2009, worldcities2013, by= c("merge", "name", "country.etc", "pop", "lat", "long"), all=TRUE)
world.cities <- world.cities[order(world.cities$merge, world.cities$capital, world.cities$pop),]
world.cities <- world.cities[!duplicated(world.cities$merge), ]
world.cities$merge <-NULL
world.cities <- world.cities[order(-world.cities$pop), ]
rm(worldcities2013, world.cities2009)
# bring country names in combined world.cities to WDi standart
source('SmallScripts/bring_country_names_in_citydata_to_WDI.R')
# create uniform country names in world.cities without special characters and lowcase
X <- world.cities$country.etc
source('SmallScripts/delete_country_special_characters.R')
world.cities$country.etc <- X
rm(X)
View(world.cities)
### list the world capital cities
data(world.cities)
world.cities$name <- tolower(world.cities$name)
world.cities2009 <- world.cities[order(-world.cities$pop, na.last=TRUE) , ]
rm(world.cities)
#The dataframe wrongly lists dehli as not being the capital of india, plus had a typo in seoul, which both we recode.
world.cities2009$capital[world.cities2009$name == "delhi" & world.cities2009$country.etc == "India"] <- "1"
world.cities2009$name[world.cities2009$name == "soul" & world.cities2009$country.etc == "Korea South"] <- "seoul"
world.cities2009$name[world.cities2009$name == "bombay" &  world.cities2009$country.etc  == "India"] <- "mumbai"
# remane some countries so they match the first city dataset better
world.cities2009$country.etc[world.cities2009$country.etc == "Russia"] <- "Russian Federation"
world.cities2009$country.etc[world.cities2009$country.etc == "UK"] <- "United Kingdom"
world.cities2009$country.etc[world.cities2009$country.etc == "USA"] <- "United States of America"
world.cities2009$country.etc[world.cities2009$country.etc == "Korea North"] <- "Korea, Democratic People's Republic of"
world.cities2009$country.etc[world.cities2009$country.etc == "Korea South"] <- "Korea, Republic of"
world.cities2009$country.etc[world.cities2009$country.etc == "Sicily"] <- "Italy"
world.cities2009$country.etc[world.cities2009$country.etc == "East Timor"] <- "Timor-Leste"
world.cities2009$country.etc[world.cities2009$country.etc == "Madeira"] <- "Portugal"
world.cities2009$country.etc[world.cities2009$country.etc == "Madiera"] <- "Portugal"
##############################################################################################
# merge the two sets: cities 2013 and cities 2009 to world.cities
#some preliminary cleaning before merging
world.cities2009$name <- gsub(" ", "", world.cities2009$name)
world.cities2009$name <- tolower(world.cities2009$name)
world.cities2009$country.etc<-gsub(" ", "",world.cities2009$country.etc, ignore.case=TRUE)
world.cities2009$country.etc<-gsub("\\,", "",world.cities2009$country.etc, ignore.case=TRUE)
world.cities2009$country.etc <- tolower(world.cities2009$country.etc)
worldcities2013$Country <- tolower(worldcities2013$Country)
# subsets and renaming so the two datasets match in their columns
worldcities2013 <- subset(worldcities2013, select =c("City", "Country", "Population", "Latitude", "Longitude", "Region"))
colnames(worldcities2013)[1] <- "name"
colnames(worldcities2013)[2] <- "country.etc"
colnames(worldcities2013)[3] <- "pop"
colnames(worldcities2013)[4] <- "lat"
colnames(worldcities2013)[5] <- "long"
#create a column to merge over: countrycity
world.cities2009$merge <- paste(world.cities2009$country.etc, world.cities2009$name, sep="")
worldcities2013$merge <- paste(worldcities2013$country.etc, worldcities2013$name, sep="")
#merge to new set: "world.cities"
world.cities <- merge(world.cities2009, worldcities2013, by= c("merge", "name", "country.etc", "pop", "lat", "long"), all=TRUE)
world.cities <- world.cities[order(world.cities$merge, world.cities$capital, world.cities$pop),]
world.cities <- world.cities[!duplicated(world.cities$merge), ]
world.cities$merge <-NULL
world.cities <- world.cities[order(-world.cities$pop), ]
rm(worldcities2013, world.cities2009)
# bring country names in combined world.cities to WDi standart
source('SmallScripts/bring_country_names_in_citydata_to_WDI.R')
# create uniform country names in world.cities without special characters and lowcase
X <- world.cities$country.etc
source('SmallScripts/delete_country_special_characters.R')
world.cities$country.etc <- X
rm(X)
###########################################
# WORLD CITY DATASET 1/2 (worldcities2013)
# here: http://download.maxmind.com/download/worldcities/worldcitiespop.txt.gz and transformed into CSV
worldcities2013 <- read.csv("City Data/worldcitiespop.csv")
# introduce Tehran as it was missing in the original dataset
worldcities2013 <- rbind(worldcities2013, data.frame(X=0,Country="ir", City="tehran", AccentCity="Tehran",
Region= 1, Latitude=35.67, Longitude=51.43,Population=7160094))
# introduce Akkaraipattu as it was missing in the original dataset
worldcities2013 <- rbind(worldcities2013, data.frame(X=0,Country="lk", City="Akkaraipattu", AccentCity="Akkaraipattu",
Region= 31, Latitude=7.227862, Longitude=81.850551,Population=35000))
# sorting by population
worldcities2013 <- worldcities2013[order(-worldcities2013$Population, na.last=TRUE) , ]
# replace 2digit coountry names by the names used in the secon city dataset
source('SmallScripts/2digit2ctry.R')
worldcities2013$City <- gsub(" ", "", worldcities2013$City)
worldcities2013$City <- tolower(worldcities2013$City)
##########################################
# WORLD CITY DATASET 2/2 (world.cities2009)
### list the world capital cities
data(world.cities)
world.cities$name <- tolower(world.cities$name)
world.cities2009 <- world.cities[order(-world.cities$pop, na.last=TRUE) , ]
rm(world.cities)
#The dataframe wrongly lists dehli as not being the capital of india, plus had a typo in seoul, which both we recode.
world.cities2009$capital[world.cities2009$name == "delhi" & world.cities2009$country.etc == "India"] <- "1"
world.cities2009$name[world.cities2009$name == "soul" & world.cities2009$country.etc == "Korea South"] <- "seoul"
world.cities2009$name[world.cities2009$name == "bombay" &  world.cities2009$country.etc  == "India"] <- "mumbai"
# remane some countries so they match the first city dataset better
world.cities2009$country.etc[world.cities2009$country.etc == "Russia"] <- "Russian Federation"
world.cities2009$country.etc[world.cities2009$country.etc == "UK"] <- "United Kingdom"
world.cities2009$country.etc[world.cities2009$country.etc == "USA"] <- "United States of America"
world.cities2009$country.etc[world.cities2009$country.etc == "Korea North"] <- "Korea, Democratic People's Republic of"
world.cities2009$country.etc[world.cities2009$country.etc == "Korea South"] <- "Korea, Republic of"
world.cities2009$country.etc[world.cities2009$country.etc == "Sicily"] <- "Italy"
world.cities2009$country.etc[world.cities2009$country.etc == "East Timor"] <- "Timor-Leste"
world.cities2009$country.etc[world.cities2009$country.etc == "Madeira"] <- "Portugal"
world.cities2009$country.etc[world.cities2009$country.etc == "Madiera"] <- "Portugal"
##############################################################################################
# merge the two sets: cities 2013 and cities 2009 to world.cities
#some preliminary cleaning before merging
world.cities2009$name <- gsub(" ", "", world.cities2009$name)
world.cities2009$name <- tolower(world.cities2009$name)
world.cities2009$country.etc<-gsub(" ", "",world.cities2009$country.etc, ignore.case=TRUE)
world.cities2009$country.etc<-gsub("\\,", "",world.cities2009$country.etc, ignore.case=TRUE)
world.cities2009$country.etc <- tolower(world.cities2009$country.etc)
worldcities2013$Country <- tolower(worldcities2013$Country)
# subsets and renaming so the two datasets match in their columns
worldcities2013 <- subset(worldcities2013, select =c("City", "Country", "Population", "Latitude", "Longitude", "Region"))
colnames(worldcities2013)[1] <- "name"
colnames(worldcities2013)[2] <- "country.etc"
colnames(worldcities2013)[3] <- "pop"
colnames(worldcities2013)[4] <- "lat"
colnames(worldcities2013)[5] <- "long"
#create a column to merge over: countrycity
world.cities2009$merge <- paste(world.cities2009$country.etc, world.cities2009$name, sep="")
worldcities2013$merge <- paste(worldcities2013$country.etc, worldcities2013$name, sep="")
#merge to new set: "world.cities"
world.cities <- merge(world.cities2009, worldcities2013, by= c("merge", "name", "country.etc", "pop", "lat", "long"), all=TRUE)
world.cities <- world.cities[order(world.cities$merge, world.cities$capital, world.cities$pop),]
world.cities <- world.cities[!duplicated(world.cities$merge), ]
world.cities$merge <-NULL
world.cities <- world.cities[order(-world.cities$pop), ]
rm(worldcities2013, world.cities2009)
# bring country names in combined world.cities to WDi standart
source('SmallScripts/bring_country_names_in_citydata_to_WDI.R')
# create uniform country names in world.cities without special characters and lowcase
X <- world.cities$country.etc
source('SmallScripts/delete_country_special_characters.R')
world.cities$country.etc <- X
rm(X)
View(world.cities)
X <- GTD$city
source('CityCleaning.R')
source('SmallScripts/delete_country_special_characters.R')
GTDcity <- X
X <- GTD$country_txt
source('SmallScripts/delete_country_special_characters.R')
GTDcountry <- X
world.cities<-WC.UC.dist
world.cities$CityID <- NULL
X<-world.cities$name
source('SmallScripts/delete_country_special_characters.R')
Cities <- X
X<-world.cities$country.etc
source('SmallScripts/delete_country_special_characters.R')
Countries <- X
world.cities["merge"] <- paste(Countries, Cities, sep="")
Testframe <- GTD[1:21]
Testframe["merge"] <-data.frame(paste(GTDcountry, GTDcity, sep=""))
PreGTD <- merge(Testframe, world.cities, by=c("merge"), all.x=TRUE)
PreGTD  <- PreGTD [order(-PreGTD$HUMscale, na.last=TRUE) , ]
rm(Testframe, t.world.cities, GTDcity, GTDcountry, X, Y)
View(PreGTD)
sum(is.na(PreGTD$country.etc))
TTT <- subset(PreGTD , select = c("merge", "city", "HUMscale", "name"), na.strings = c("", " "))
View(TTT)
GTDWDI <-merge(PreGTD, WDIData, by.x=c("country_txt", "iyear"), by.y=c("country", "year"), all.x=TRUE, sort=TRUE)
View(GTDWDI)
GTDWDI <-merge(GTD, WDIData, by.x=c("country_txt", "iyear"), by.y=c("country", "year"), all.x=TRUE, sort=TRUE)
View(GTDWDI)
GTDWDI <-merge(PreGTD, WDIData, by.x=c("country_txt", "iyear"), by.y=c("country", "year"), all.x=TRUE, sort=TRUE)
View(GTDWDI)
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
########################################################################################
########################################################################################
############################   GATHERING  DATA    ######################################
########################################################################################
########################################################################################
############################################
###### The Global Terrorism Database  ######
############################################
############################################
#Load the Global Terrorism Database (GTD). It is open souce and can be downloaded after registration at
# http://www.start.umd.edu/gtd/contact/
rawGTD <- read.csv("Terror Data/globalterrorismdb_0814dist.csv", header=TRUE)
#The (GTD) contains over a 120k observations on more than 120 variables. We don't need them all.
#We therefore filter the database to make it fit our needs, erasing over a 100 variables.
#We only want to look at successfull terror attacks and include basic data on time, location and target.
GTD <- subset(rawGTD, select = c(eventid, iyear, imonth, iday, country, country_txt, region, provstate, region_txt, city, attacktype1, targtype1, targsubtype1,
weaptype1, weapsubtype1, propextent, nkill, nwound),
iyear >= 1970 & success == 1, na.strings = c("", " "))
rm(rawGTD)
#Next we order the GTD)
GTD <- GTD[order (GTD$country_txt, GTD$iyear, GTD$imonth, GTD$iday, GTD$city), ]
############################################
#We introduce our first scale: "Targets Urbanity Potential Scale (TUPscale)"
GTD["TUPscale"] <- GTD$targsubtype1
GTD$TUPscale <- recode(GTD$TUPscale, "40:42 = 9; 9 = 0; 27:35 = 0; 37:39 = 0; 65 = 0; 72 = 0; 1 = 2; 4:5 = 2; 10 = 2;
12 = 2; 53:56 = 2; 58:59 = 2; 61:62 = 2; 82 = 2; 95:96 = 2;6 = 9; 13 = 9; 104:108 = 9;
51:52 = 9; 57 = 9; 60 = 9; 63:64 = 9; 73 = 9; 80:81 = 9; 88:92 = 9; 98 = 9; 2 = 7; 3 = 7;
7:8 = 7; 44 = 7; 48:50 = 7; 67:71 = 7; 74:79 = 7; 83:87 = 7; 97 = 7; 99 = 7; 14:26 = 9;
100:103 = 9; 111 = 9; 109 = 9; 110 = 9; 36 = 9; 43 = 9; 45:47 = 9; 66 = 9; 93:94 = 9;
11 = 9", as.numeric.result=TRUE)
# 0= Rural & Military; 2= Government & Police; 3= Potentilly Urban Workplace; #7= Potentilly Urban Infrastructure;
# 9= Potentilly Expression of Urban Core Life
############################################
# We introduce our second scale: "Extent of Property Damage (PROPscale)" and write it back into the GTD
GTD["PROPscale"] <- GTD$propextent
GTD$PROPscale <- as.numeric(GTD$PROPscale)
#Bring the values to the $ values coded in the originally coded categories.
GTD$PROPscale <- recode(GTD$PROPscale, "1=1000000000; 2=1000000; 3=1000; 4=0; NA=NA")
############################################
# We introduce our third scale: "Extent of Human Damage (HUMscale)" which adds wounded and killed /and write it back into the GTD
GTD["HUMscale"] <- GTD$nkill+GTD$nwound
GTD$HUMscale <- as.numeric(GTD$HUMscale)
GTDWDI <-merge(GTD, WDIData, by.x=c("country_txt", "iyear"), by.y=c("country", "year"), all.x=TRUE, sort=TRUE)
View(GTDWDI)
X <- GTD$city
source('CityCleaning.R')
source('SmallScripts/delete_country_special_characters.R')
GTDcity <- X
X <- GTD$country_txt
source('SmallScripts/delete_country_special_characters.R')
GTDcountry <- X
world.citiesUC<-WC.UC.dist
world.citiesUC$CityID <- NULL
X<-world.citiesUC$name
source('SmallScripts/delete_country_special_characters.R')
Cities <- X
X<-world.citiesUC$country.etc
source('SmallScripts/delete_country_special_characters.R')
Countries <- X
world.citiesUC["merge"] <- paste(Countries, Cities, sep="")
Testframe <- GTD[1:21]
Testframe["merge"] <-data.frame(paste(GTDcountry, GTDcity, sep=""))
PreGTD <- merge(Testframe, world.citiesUC, by=c("merge"), all.x=TRUE)
PreGTD  <- PreGTD [order(-PreGTD$HUMscale, na.last=TRUE) , ]
View(GTD)
View(GTDWDI)
