summary(ability.cov)
summay(women)
summary(women)
women
sleep
sleep {datasets}
help (sleep)
help (state)
state.area
state.x77:Murder
state.Murder77
state.x77.Murder
state.x77
'women'
clear
clear (women)
reset (women)
help functions
functions
women
women$weight <- women$weight * 0.45359237 # convert lb to kg
women$height <- women$height * 0.0254  # convert in to m
summary (women)
> women
> women
> women$weight <- women$weight * 0.45359237 # convert lb to kg
> women$height <- women$height * 0.0254  # convert in to m
> summary (women)
women
women
women$weight <- women$weight * 0.45359237 # convert lb to kg
women$height <- women$height * 0.0254  # convert in to m
summary (women)
women$weight <- women$weight / 0.45359237 # convert lb to kg
women$height <- women$height / 0.0254  # convert in to m
summary (women)
boxplot(women$height, main = 'Average Heights for American Women')
boxplot(women$height, main = 'Average Heights for American Women "(m)"')
boxplot(women$height, main = 'Average Heights for American Women (m)')
cor.test(log(women$height), women$height)
boxplot(women$weight, main = 'Average Weight for American Women (kg)')
plot(women, xlab = "Height (m)", ylab = "Weight (kg)",main = "women data: American women aged 30-39"
source
plot(women, xlab = "Height (m)", ylab = "Weight (kg)",main = "women data: American women aged 30-39"
)
setwd('C:\Users\Lokus\Documents\GitHub\TestS18')
setwd('~\Users\Lokus\Documents\GitHub\TestS18')
setwd('~Users\Lokus\Documents\GitHub\TestS18')
setwd('~/Users/Lokus/Documents/GitHub/TestS18')
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
### Fall 2014
### Instructor: Christopher Gandrud
##########################
###### ASSIGNMENT 1 ######
##########################
##### Part 1: Murder #####
##########################
#by Lukas B and Cameron R#
##########################
### 25. September 2014 ###
##########################
# choosing some data from the core R data sets on US States statistics
data(state)
# getting some details about the data set
?state
# state.x77 is a interetsing matrix, we go on with this one
state.x77
# pulling out the "state.x77" matrix with 50 rows and 8 columns giving some statistics in the respective columns
statedata1 <- data.frame(state.x77, state.x77, stringsAsFactors = FALSE)
# focusing on Murder and getting additional information about it (Murder and Non-negligent Manslaughter rate per 100,000 Population (1976))
summary(statedata1$Murder)
# making a barplot showing murder rate by state
barplot(statedata1$Murder, main="Murder and Non-negligent Manslaughter rate per 100,000 Population (1976)", names.arg = state.abb, las=2, xlab="US States", space=1)
# we did not do the "setwd" with harddrive directory thing, as we were working on github online only
# hopefully this works instead
install.packages("devtools")
source_url('http://github.com/LBRETZIN/TestS18/blob/TestBranch/A1women.txt')
# the end :)
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
### Fall 2014
### Instructor: Christopher Gandrud
##########################
###### ASSIGNMENT 1 ######
##########################
##### Part 2:  Women #####
##########################
#by Lukas B and Cameron R#
##########################
### 25. September 2014 ###
##########################
# looking at some data on American women
data(women)
# analyse the data
summary (women)
# converting to something the rest of the world would understand
women$weight <- women$weight * 0.45359237 # from lb to kg
women$height <- women$height * 0.0254  # from in to m
# drawing boxplots for heigth...
boxplot(women$height, main = 'Average Heights for American Women aged 30–39 (m)')
# ...and weight
boxplot(women$weight, main = 'Average Weight for American Women aged 30–39 (kg)')
# plotting height and weight on a simple scatter plot
plot(women, xlab = "Height (m)", ylab = "Weight (kg)",main = "American women aged 30-39")
# and testing for the simple correlation that became obvious
cor.test(log(women$height), women$height) # test correlation between height and weight
# the end
---
title: "Research Proposal - A Turn Toward Urban"
author: "Sascha Schuster, Lukas Bretzinger, Cameron Reed"
date: "October 24, 2014"
output:
pdf_document:
toc: true
bibliography:
- BiblioProposal.bib
---
*This is the explanation for our research question and preparation of data for statistical analysis (assignment 2).*
# Topic and Relevance
In the past five years, violent extremist groups have attracted significant attention using urban centers as stages.  In 2008, Pakistan-based Lashkar-e-Taiba launched a coordinated assault on Mumbai, India which lasted three days and resulted in 164 civilian deaths.  In 2013, Somalia-based Al-Shabaab infiltrated the Westgate mall in Nairobi, Kenya, killing 67 and injuring 175 civilians.  Terrorist groups are a tremendous threat to vulnerable cities.  In both cases, the groups exploited with relative ease the complex flow of systems in the city to achieve desired outcomes. This sparked a debate about terrorist groups' targeting practices and on how to locate, understand, protect against, and mitigate attacks in the face of megatrends like urbanization, population growth, migration, and connectedness.  The urban environment emerges as a unit of analysis for acts of political violence. Future conflicts are expected to take place in crowded, urban, coastal and connected environments instead of landlocked, remote and rural ones. Especially megacities present fertile grounds for inequality and conflict, as well as the most connected, large, yet vulnerable human and physical sub-system for terrorist attacks.  Since 9/11, the fields of geography, urban studies, political science, and many others have contributed to the understanding of terrorist attacks, strategic decision-making, and geospatial aspects of terrorists' targeting behavior. We conduct a large-N analysis using the Global Terrorism Database to illuminate trends in targeting behavior.  Our study aims to fill a gap: On a global scale, is there a trend for terrorists to target urban over rural environments?
# Literature Review
## General
Urban terrorism is by no means a new concept, as it arises in guerilla, riot, and insurgency literature [@Crenshaw1981; @Grabosky1979; @Grabosky1988; @Karber1971; @Laqueur1977; @Lupsha1967].  Indeed, the urban context was a feature of Walter Laquerâs early study on the guerilla warfare. Groups like the Mau Mau of Kenya, the Irish Republican Army, and the Front de Liberacion Nationale employed tactics against colonial powers that exhibited characteristics of urban life and space [@Laqueur1977].  Martha Crenshawâs seminal piece on the causes of terrorism highlighted the enduring importance of modernization and urbanization, which she saw as an ever growing opportunity for terrorist groups to execute attacks [@Crenshaw1981]. Others highlight the urban space as a ground for recruitment, hiding and communication, as well as the variety of possible targets [@Grabosky1979].  Most of the literature leading up to 9/11 recognized the urban element, but did not fully address linkages between urbanization and state security, let alone Islamic terrorism as a mass phenomena, which would later dominate discourses in the early 21st century.
Insights on terrorist groupâs targeting and decision-making lead in different directions, which shape the way the field of terrorism studies has grown in the recent years. The literature explains various reasons for targeting practices, such as instrumental means, i.e., resources and capabilities driving strategy, organizational survival, management, human resources, and funding constraining strategic decisions, or ideological and religious motivation.  More specifically, targeting behavior has been growing in importance in terrorism literature due to its policy relevance and potential for prediction.  Martha Crenshaw has shed light on how groups shape motivations behind targeting, such as religiosity, communal ties, or other less tangible, intrinsic motivations [@Crenshaw1981].  Todd Sandler built strategic game theory models that parse potential decisions with constraints of resources and capabilities taken into consideration [@Enders2000].  Other theorists believe that organizational survival drives decisions, such as Jacob Shapiroâs economic insights into how covert organizations are limited by their ability to fund operations, also known as rational choice [@Shapiro2007].  Finally, scholars have thoroughly explored characteristics of organizations that elongate or decline lifespans, including analysis of favorable conditions for organizational survival [@Blomberg2011].  Of course, these theories are not mutually exclusive and they collectively strengthen the understanding of strategic considerations in terrorist decision-making.
However, theories of strategy do not take into consideration geospatial aspects or variation in targeting behavior.  Consider the following questions.  Does the organization want to control territory or not?  Or do they rather want to make a point, provoke a government in the realm of national symbolism, or attract attention?  Apart from explaining internal factors of the organization, we can attempt to explain geography-bound terrorism, such as considerations of spatial and hierarchical diffusion, currently nascent in the literature on terrorist group dynamics [@Bahgat2013].  Spatial diffusion refers to one base of operations close to a series of attacks, whereas hierarchical diffusion is the existence of several hot spots from which attacks emanate.  These phenomena are supported by findings on geolocated IRA attacks in Northern Ireland and Great Britain.  The difference here in spatial and hierarchical diffusion refers to a growing sense-making literature on the spatial logic of terrorism, but also growing importance of, as Bahgat and Medina put it, âhow cities of high population and administrative worth to the government appear to have become the main targets of modern-day terrorism for a variety of strategic and cost-effective reasonsâ [@Bahgat2013].
Prominent theorists of conflict re-problematize the issue, taking into consideration megatrends of urbanization, population growth and connectedness. Megacities are their unit of analysis for studying conflict [@Kilcullen2013]. Geographers have offered a research agenda for their field in the face of the rising importance of the ancient social phenomena of terrorism [@Cutter2003]. It is often assumed that growing and developing urban environments become increasingly attractive as targets for violent extremists, resulting in more attacks on urban systems, but mostly single case studies like in the Mumbai 2008 case are referenced in support of that claim, larger empirical studies are rare [@Beall2006; @Glaeser2002; @Graham2008; @Sassen2010; @Savitch2001). It said to be an traditional characteristic of terrorism studies that much is written on the basis on little empirical analysis [@Jongman1988]. To our knowledge, a comparable study exists only on the geolocation of terror attacks on the U.S. level [@Webb2009].
## Statistical Methods, Research, and GTD Use
Fortunately, the Global Terrorism Database (GTD) has been used in a variety of ways and by a wide range of fields to study terrorism.  Also, the GTD has been utilized to study a specific categorical phenomenon or region, e.g, hostage-taking or weapon type, as well as sweeping trends, such as casualty rates due to terrorist attacks.  The methods used to study the GTD are also important to mention: GIS, descriptive statistics, and qualitative inquiry [@LaFree2009a].
There are essentially three camps of researchers in the applied fields using the GTD:
1. Geography
2. Political Science/International Relations
3. Terrorism Studies
In most of the cases, there is a convergence of the three albeit to different extents.  For example, geographers use the data to make sense of geospatial path dependencies of terrorist groups and social network analysis (physical and human geography), whereas political scientists use the data to undertake more rigorous qualitative analysis and counter conventional beliefs about security and war.  Often, terrorism scholars will focus on one category, region, group, or trajectory.  LaFree is producing the most comprehensive review of uses of the GTD, which comes out in 2015.  He also has written extensively on how to use the GTD to counter widely held beliefs regarding terrorism [@LaFree2009].  Correlation work between terrorism and economic, legal, or group characteristic data also exists [@LaFree2010].  This body of work might be viewed as functional.  Geospatial analysis of these trends gained traction after 9/11 and have since been growing in importance and policy relevance.  Operating under the assumption that large-scale attacks are planned, geospatial analysis, or mapping other types of analysis onto geographical illustrations, provide insights into strategies of targeting and decision-making.  In fact, applied geographers have discovered trends in the environment that signal a trend toward targeting areas with high populations [@Bahgat2013].  The cross-fertilization of the three fuels our study.
**Research question**:  What are the trends in terrorism targeting urban vs. rural spaces?
This is a purely descriptive question, looking at what the data can show us up to this point.
# Data
## Data Set
**Data**: Global Terrorism Database (GTD) [@START2013]
We will use the START Global Terrorism Database (GTD), as it is the most comprehensive open source database on terrorist attacks [@LaFree2006].  The data ranges from 1970-2013, logs 125,000 terrorist attacks, and uses 45 - 120 variables per attack.  Among other information, the GTD holds records on the location, the target, and the damage caused by attacks [@START2014]. It is a simple .xls file, available after creating an account on the GTD Projects website and it is already tuned towards being turned into a .csv, as close to no excel functions are layered over the data entry. It contains both numeric and factor variables for describing the attacks characteristics. All categorical variables have both categorical numbers and a respective text variable for each number. This creates a lot of redundant information and needs a long tidying process.
The current GTD is the product of several phases of data collection efforts, each relying on publicly available, unclassified source materials.  These include media articles and electronic news archives, and to a lesser extent, existing data sets, secondary source materials such as books and journals, and legal documents [@START2014]. We are aware of the entangled problems of reliability and comparability.
The original set of incidents that comprise the GTD occurred between 1970 and 1997 and were collected by the Pinkerton Global Intelligence Service (PGIS)âa private security agency.  PGIS data collection efforts are remarkable in that they were able to develop and apply a similar data collection strategy for a 28-year period [@LaFree2006]. After START completed digitizing these handwritten records in 2005, they collaborated with the Center for Terrorism and Intelligence Studies (CETIS) to continue data collection beyond 1997 and expand the scope of the information recorded for each attack [@START2014]. CETIS collected GTD data for terrorist attacks that occurred from January 1998 through March 2008, after which ongoing data collection transitioned to the Institute for the Study of Violent Groups (ISVG). ISVG continued as the primary collector of data on attacks that occurred from April 2008 through October 2011.
GTD staff based at START headquarters at the University of Maryland integrated and synthesized data collected across the entire 1970-2013 time span with the goal of ensuring that the definitions and methodology are as consistent as possible across all phases of data collection. In addition, GTD staff at START retroactively coded several key variables not originally available for the PGIS cases, conducted numerous quality control projects, and supplemental data collection efforts. These supplemental data collection efforts involve systematically comparing a variety of additional sources of terrorism incident data to the GTD to identify any missing events that satisfy GTD inclusion criteria. GTD staff research these missing events to identify primary sources of information and code the attack details for addition to the GTD.   Beginning with cases that occurred in November 2011, all ongoing GTD data collection is conducted by START staff at the University of Maryland.  Additional information on the history and data collection methodology of the database can be found on the GTD website [@START2014].
Given the varied context of GTD data collection, the database another source of general inconsistency: Legacy issues--the GTD now includes incidents of terrorism from 1970 to 2013, however a number of new variables were added to the database beginning with the post-1997 data collection effort. Wherever possible, values for these new variables were retroactively coded for the original incidents, however some of the new variables pertain to details that were not recorded in the first phase of data collection.  For any newly added variables that were not retroactively coded, they only exist for post-1997 cases.
GTD is based on PGIS and PGIS is the most granular and comprehensive.  To illustrate how consequential these coding differences are we compare terrorism event counts for 1997 between the PGIS database and the U.S. State Department terrorism database. In that year, the Department of State records 304 acts of international terrorism, which caused 221 deaths and 683 injuries. For the same year, the PGIS data reports on 3,523 acts of terrorism and political violence that claimed 3,508 lives and inflicted 7,753 injuries [@LaFree2006].
## Statistical Methodology
**Variable**: Urbanity of terroristsâ targets.
The GTD defines a terrorist attack as the threatened or actual use of illegal force and violence by a non-state actor to attain a political, economic, religious, or social goal through fear, coercion, or intimidation. In order to consider an incident for inclusion in the GTD, all three of the following attributes must be present:
1. The incident must be intentional.
2. The incident must entail some level of violence or threat of violence--including damage to property and violence against people.
3. The perpetrators of the incidents must be sub-national actors.
*Note: The database does not include acts of state terrorism.*
In order to use the database, we have to stick to the definitions given, limiting us to non-state terrorism.
We will build on definitions of urbanization from the standpoint of urban studies and security, while geography will help us mostly in finding measurable indicators.  To speak to literature on conflict, we conceptualize urbanity to include a static, geospatial dimension, not purely socially co-constructed spaces of human interaction / communication alone. How can we still cover connectedness, embeddedness, or a sense of being networked or plugged in?  In other words, what parts of the constructed environment âareâ the human environment, and how can we justify and measure that? It has to be permanent, relatively densely populated, and confined in terms of economic, cultural and social characteristics. The interconnectedness and interdependency (partly expressed in infrastructure of different kinds) of urban life is part of our concept, on top of being a permanent and dense human settlement. Urbanity is measured on a continuous spectrum. It is not a binary concept.
The measure for the âurbanity of the targetâ has two components for us, location and target. To give an idea on how to measure both:
1. *Location*: There are many ways to determine, if an attack took place in an urban environment. As GPS coordinates are available for the time after 2001, potentially one could find a way to include land use, population density and proximity to urban center in the analysis of the attack. This likely exceeds resources and time available to us. If we include the idea that our research interest lays in the intention to target urban life and space, then we can use another measure. This would be the relative size and importance of the city compared to the national and regional environment. We assume that a terrorist organization can choose between targets at least on a national level, and put together our own probably quickly hand-collected dataset with city like: 100 largest cities of the for each decade; largest cities for each county (between 2 and 25 depending on the countryâs population determined with a simple mathematical formula); costal âMegacitiesâ for each decade; âWorld Citiesâ for each decade. To combine the lists in a data frame, the vector names might be: Name of the city, hundred_largest_70s, hundred_largest_80s, hundred_largest_90s, hundred_largest_20s,  100 largest 21s, large_national_decade, megacity_decade, worldcity_decade, costal, capitalâ¦ whereas anything but the name is a 0-1 binary.
2. *Target*: The target of the attack is coded in the GTD dataset with target and subtarget type. In order to weight them in terms of their representation of urbanity, we created categories of targets that represent aspects of urban life and space, with varying degrees: Expression of urban life (restaurant, hotel, apartment, etc.); infrastructure necessary to sustain urban life (water supply, port, electricity, etc.); employment (construction, factory, multinational corporation); police and governance; military and rural.
Merging the datasets over cities will be easy but special cases of city renaming must be accounted for, like East and West Berlin/Berlin, Bombay/Mumbai, etc. The combined dataset basically adds to the GTD a variable for potential urbanity of the targets and adds variables of quality to various cities due to their respective characteristics in relation to their national and regional peers.
# Analysis
The analysis will focus on multivariate statistical regression models for describing a potential trend in the urbanity of terror attacks in terms of the chosen city and the chosen target over time. Descriptive inference such that our results will leads us to reject a null hypothesis that attacks have not changed over time in targeting urban life and space that goes beyond the growth of this space over time.
To include the success of the attacks, weights for killed and injured humans will be added to each attack, as well as property damage in a second round. It might be necessary to manipulate the property damage in terms of the relative wealth of the country to account in country variation in the potential wealth that can be destroyed.
Necessary controls are the:
*Relative growth of urban life and space on the country scale (World Bank Data)
*Civil war (1-0 dummy from the Correlates of War (COW) Project, Intra-State War Database 4.0 which is the most updated one)
*Capital Cities (coded by hand)
After finding a possible correlation between time and targets urbanity and locations urbanity, analyzing trends in targeting behavior on the regional, country, or group level will be easy to execute as the GTD contain variables for all attacks.
# References
library(RCurl)
geturl("http://bit.ly/1sjaJ2M", ssl.verifypeer=0L, followlocation=1L, destfile="GTD.csv", quiet = TRUE)
getURL("http://bit.ly/1sjaJ2M", ssl.verifypeer=0L, followlocation=1L, destfile="GTD.csv", quiet = TRUE)
getURL("http://bit.ly/1sjaJ2M", ssl.verifypeer=0L, followlocation=1L)
#download a limited GTD we created for this assignment (5MB instead of 100MB) file
GTD_in_Memory <- getURL("http://bit.ly/1sjaJ2M", ssl.verifypeer=0L, followlocation=1L)
writeLines(GTD_in_Memory,'GTD.csv')
#download a limited GTD we created for this assignment (5MB instead of 100MB) file
GTD_in_Memory <- getURL("http://bit.ly/1sjaJ2M", ssl.verifypeer=0L, followlocation=1L)
writeLines(GTD_in_Memory,'GTD.csv')
#Load the Global Terrorism Database
rawGTD <- read.csv("GTD.csv", header=TRUE)
#download a limited GTD we created for this assignment (5MB instead of 100MB) file
GTD_in_Memory <- getURL("http://bit.ly/1sjaJ2M", ssl.verifypeer=0L, followlocation=1L)
writeLines(GTD_in_Memory,'GTD.csv')
#Load the Global Terrorism Database
rawGTD <- read.csv("GTD.csv", header=TRUE)
#download a limited GTD we created for this assignment (5MB instead of 100MB) file
GTD_in_Memory <- getURL("http://bit.ly/1sjaJ2M", ssl.verifypeer=0L, followlocation=1L)
writeLines(GTD_in_Memory,'GTD.csv')
#Load the Global Terrorism Database
rawGTD <- read.csv("GTD.csv")
library(RCurl)
#download a limited GTD we created for this assignment (5MB instead of 100MB) file
GTD_in_Memory <- getURL("http://bit.ly/1sjaJ2M", ssl.verifypeer=0L, followlocation=1L)
writeLines(GTD_in_Memory,'GTD.csv')
rawGTD <- read.csv(GTD_in_Memory)
rawGTD <- read.csv("GTD_in_Memory)
rawGTD <- read.csv("GTD_in_Memory")
#The Global Terror Database (GTD) we are using for our analysis contains over a 120k observations on more than 120 variables.
rawGTD <- read.csv("GTD_in_Memory")
#download a limited GTD we created for this assignment (5MB instead of 100MB) file
GTD_in_Memory <- getURL("https://rawgit.com/SaschaSchuster/CSSDA_Assignment2_UrbanTerror/master/GTD.csv", ssl.verifypeer=0L, followlocation=1L)
writeLines(GTD_in_Memory,'GTD.csv')
#Load the Global Terrorism Database
rawGTD <- read.csv("GTD.csv", header=TRUE)
glds00ag60 <- read.table("C:/Users/Lokus/Downloads/glds00ag60.asc", quote="\"")
View(glds00ag60)
glds00ag <- read.table("C:/Users/Lokus/Downloads/glds00ag.asc", quote="\"")
View(glds00ag)
View(glds00ag)
worldcitiespop <- read.csv("C:/Users/Lokus/Downloads/worldcitiespop.txt")
View(worldcitiespop)
View(worldcitiespop)
View(worldcitiespop)
find
find(ravensburg)
download a limited GTD we created for this assignment (5MB instead of 100MB) file
GTD_in_Memory <- getURL("https://rawgit.com/SaschaSchuster/CSSDA_Assignment2_UrbanTerror/master/GTD.csv", ssl.verifypeer=0L, followlocation=1L)
writeLines(GTD_in_Memory,'GTD.csv')
#Load the Global Terrorism Database
rawGTD <- read.csv("GTD.csv", header=TRUE)
#Load basic R packages
library(foreign)
library(car)
library(ggplot2)
library(RCurl)
#download a limited GTD we created for this assignment (5MB instead of 100MB) file
GTD_in_Memory <- getURL("https://rawgit.com/SaschaSchuster/CSSDA_Assignment2_UrbanTerror/master/GTD.csv", ssl.verifypeer=0L, followlocation=1L)
writeLines(GTD_in_Memory,'GTD.csv')
#Load the Global Terrorism Database
rawGTD <- read.csv("GTD.csv", header=TRUE)
GTD <- subset(rawGTD, select = c(eventid, iyear, imonth, iday, country, region, attacktype1, targtype1, targsubtype1, propextent, nkill, nwound),iyear >= 1970, na.strings = c("", " "))
View(GTD)
View(rawGTD)
View(worldcitiespop)
citieswithpop <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude, Population),Population >= 1, na.strings = c("", " "))
View(worldcitiespop)
View(worldcitiespop)
citieswithpop <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population != NA, na.strings = c("", " "))
View(citieswithpop)
citieswithpop <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population != NA)
citieswithpop <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude), Population != NA)
citieswithpop <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude), Population != "NA")
View(citieswithpop)
citieswithpop <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population != "NA")
View(citieswithpop)
View(worldcitiespop)
View(citieswithpop)
### cities with a known population with more than 50000 inhabitants
citieswithpop <- subset(worldcitiespop, select =
c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > 50000)
)
### cities with a known population with more than 50000 inhabitants
citieswithpop <- subset(worldcitiespop, select =
c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > "50000")
View(citieswithpop)
### cities with a known population with more than 1000000 inhabitants
citieswithpop <- subset(worldcitiespop, select =
c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > "50000")
## cities with a known population with more than 1000000 inhabitants
citieswithpop <- subset(worldcitiespop, select =
c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > "1000000")
View(citieswithpop)
### cities with a known population with more than 1.000.000.0 inhabitants
citieswithpop <- subset(worldcitiespop, select =
c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > "10000000")
### cities with a known population with more than 1.000.000.0 inhabitants
citieswithpop <- subset(worldcitiespop, select =
c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > "100000000")
### cities with a known population with more than 1.000.000.0 inhabitants
citieswithpop <- subset(worldcitiespop, select =
c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > "100000000")
View(citieswithpop)
### cities with a known population with more than 1.000.000.0 inhabitants
citieswithpop <- subset(worldcitiespop, select =
c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > "50000000")
View(citieswithpop)
### cities with a known population with more than 1.000.000.0 inhabitants
citieswithpop <- subset(worldcitiespop, select =
c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population => 5000)
### cities with a known population with more than 1.000.000.0 inhabitants
citieswithpop <- subset(worldcitiespop, select =
c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > 5000)
View(citieswithpop)
### cities with a known population with more than 1.000.000.0 inhabitants
citieswithpop <- subset(worldcitiespop, select =
c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > 500000)
View(citieswithpop)
View(citieswithpop)
worldcitiespop <- read.csv("C:/Users/Lokus/Dropbox/Master Thesis/GitHub-Repo/UrbanTerror/worldcitiespop.txt")
View(worldcitiespop)
View(worldcitiespop)
#############################
###building a city dataset###
#############################
worldcitiespop <- read.csv("worldcitiespop.txt")
### cities with a known population with more than 500000 inhabitants
C-620big <- subset(worldcitiespop, select =
c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > 500000)
worldcitiespop <- read.csv("worldcitiespop.txt")
### cities with a known population with more than 500000 inhabitants
C-620big <- subset(worldcitiespop, select =
c(Country, City, AccentCity, Region, Latitude, Longitude, Population) Population > 500000)
worldcitiespop <- read.csv("worldcitiespop.txt")
### cities with a known population with more than 500000 inhabitants
C-620big <- subset(worldcitiespop, select =
c(Country, City, AccentCity, Region, Latitude, Longitude, Population) Population > 500000)
worldcitiespop <- read.csv("worldcitiespop.txt")
### cities with a known population with more than 500000 inhabitants
C620big <- subset(worldcitiespop, select =
c(Country, City, AccentCity, Region, Latitude, Longitude, Population) Population > 500000)
C620big <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > 500000)
View(`C620big`)
### cities with a known population with more than 330000 inhabitants
C620big <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > 330000)
worldcitiespop <- read.csv("worldcitiespop.txt")
### cities with a known population with more than 333000 inhabitants
C620big <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > 333000)
C620big <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > 333333)
View(`C620big`)
View(`C620big`)
View(worldcitiespop)
View(`C620big`)
install.packages("httr")
install.packages("dplyr")
install.packages("XML")
library(httr)
library(dplyr)
library(XML)
URL <- 'http://en.wikipedia.org/w/index.php?title=List_of_urban_areas_by_population&section=2'
# Get and parse all tables on the webpage
table <- readHTMLTable(URL)
UrbanCenters <- table [[2]]
UrbanCenters$City <- gsub("\\[.+?\\]","", UrbanCenters$City)
UrbanCenters$City <- gsub("\\(.+?\\)","", UrbanCenters$City)
UrbanCenters$City <- gsub("[[:digit:]]", "", UrbanCenters$City)
UrbanCenters$City <- gsub("[[:punct:]]", "", UrbanCenters$City)
View(UrbanCenters)
UrbanCenters["AccentCity"] <- UrbanCenters$City
try <- merge(c620big, UrbanCenters, by=c(AccentCity))
try <- merge(C620big, UrbanCenters, by=c(AccentCity))
try <- merge(C620big, UrbanCenters, by=c("AccentCity"))
View(try)
#############################
###building a city dataset###
#############################
worldcitiespop <- read.csv("worldcitiespop.txt")
### cities with a known population with more than 333000 inhabitants
C620big <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > 1000000)
install.packages("httr")
install.packages("dplyr")
install.packages("XML")
library(httr)
library(dplyr)
library(XML)
URL <- 'http://en.wikipedia.org/w/index.php?title=List_of_urban_areas_by_population&section=2'
# Get and parse all tables on the webpage
table <- readHTMLTable(URL)
UrbanCenters <- table [[2]]
UrbanCenters$City <- gsub("\\[.+?\\]","", UrbanCenters$City)
UrbanCenters$City <- gsub("\\(.+?\\)","", UrbanCenters$City)
UrbanCenters$City <- gsub("[[:digit:]]", "", UrbanCenters$City)
UrbanCenters$City <- gsub("[[:punct:]]", "", UrbanCenters$City)
UrbanCenters["AccentCity"] <- UrbanCenters$City
try <- merge(C620big, UrbanCenters, by=c("AccentCity"))
install.packages("httr")
install.packages("dplyr")
worldcitiespop <- read.csv("worldcitiespop.txt")
### cities with a known population with more than 333000 inhabitants
C620big <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > 1000000)
library(httr)
library(dplyr)
library(XML)
URL <- 'http://en.wikipedia.org/w/index.php?title=List_of_urban_areas_by_population&section=2'
# Get and parse all tables on the webpage
table <- readHTMLTable(URL)
UrbanCenters <- table [[2]]
UrbanCenters$City <- gsub("\\[.+?\\]","", UrbanCenters$City)
UrbanCenters$City <- gsub("\\(.+?\\)","", UrbanCenters$City)
UrbanCenters$City <- gsub("[[:digit:]]", "", UrbanCenters$City)
UrbanCenters$City <- gsub("[[:punct:]]", "", UrbanCenters$City)
UrbanCenters["AccentCity"] <- UrbanCenters$City
try <- merge(C620big, UrbanCenters, by=c("AccentCity"))
View(try)
### cities with a known population with more than 333000 inhabitants
C620big <- subset(worldcitiespop, select = c(Country, City, AccentCity, Region, Latitude, Longitude, Population), Population > 10000)
library(httr)
library(dplyr)
library(XML)
URL <- 'http://en.wikipedia.org/w/index.php?title=List_of_urban_areas_by_population&section=2'
# Get and parse all tables on the webpage
table <- readHTMLTable(URL)
UrbanCenters <- table [[2]]
UrbanCenters$City <- gsub("\\[.+?\\]","", UrbanCenters$City)
UrbanCenters$City <- gsub("\\(.+?\\)","", UrbanCenters$City)
UrbanCenters$City <- gsub("[[:digit:]]", "", UrbanCenters$City)
UrbanCenters$City <- gsub("[[:punct:]]", "", UrbanCenters$City)
UrbanCenters["AccentCity"] <- UrbanCenters$City
try <- merge(C620big, UrbanCenters, by=c("AccentCity"))
View(try)
intsall.package(maps)
intsall.packages(maps)
intsall.packages("maps")
install.packages("maps")
library(maps)
map("state", proj="bonne", param=45, fill=TRUE, plot=FALSE)
area.map(m, "North Dakota")
m<- map("state", proj="bonne", param=45, fill=TRUE, plot=FALSE)
area.map(m, "North Dakota")
m<- map("state", proj="bonne", param=45, fill=TRUE, plot=FALSE)
area.map(m, "North Dakota")
map(usa)
map('usa')
map()
data(world.cities)
View(world.cities)
m <- subset(world.cities, capital = "1")
View(m)
m <- subset(world.cities, select = c(name, capital = "1")
)
View(world.cities)
m <- subset(world.cities, select = c(name, capital = 1))
m <- subset(world.cities, select = c(name, capital = 1))
View(m)
m <- subset(world.cities, select = c(name, capital < 0))
View(m)
m <- subset(world.cities, select = c(name, capital == 0))
m <- subset(world.cities, select = c(name, capital == 1))
View(m)
m <- subset(world.cities, select = name), capital == 1)
m <- subset(world.cities, select = name, capital == 1)
View(m)
View(m)
View(m)
m <- subset(world.cities, select = name, capital == 2)
View(m)
m <- subset(world.cities, select = name, capital == 3)
View(m)
m <- subset(world.cities, select = name, capital == 1)
View(m)
source('PreAnalysis/createpregtd.R')
setwd("C:/Users/Lokus/Dropbox/UrbanTerror")
source('PreAnalysis/createpregtd.R')
# MPP-E1180: Introduction to Collaborative Social Science Data Analysis
### Fall 2014
### Instructor: Christopher Gandrud
############################
####### URBAN TERROR #######
############################
###### Part 1: Data   ######
############################
#Lukas B Cameron R Sascha S#
############################
###### Cleaning Data  ######
############################
#Loading R packages using @stevenworthington's ipak.R gist from https://gist.github.com/stevenworthington/3178163.
# ipak function: install and load multiple R packages.
# check to see if packages are installed. Install them if they are not, then load them into the R session.
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
# usage
packages <- c("foreign", "car", "RCurl", "ggplot2", "WDI", "httr", "iterators", "dplyr", "plyr",
"XML", "maps", "ggmap", "Imap", "geosphere", "maptools", "rgeos", "foreach")
ipak(packages)
rm(packages)
rm(ipak)
########################################################################################
########################################################################################
############################   GATHERING  DATA    ######################################
########################################################################################
########################################################################################
############################################
###### The Global Terrorism Database  ######
############################################
############################################
#Load the Global Terrorism Database (GTD). It is open souce and can be downloaded after registration at
# http://www.start.umd.edu/gtd/contact/
rawGTD <- read.csv("Terror Data/globalterrorismdb_0814dist.csv", header=TRUE)
#The (GTD) contains over a 120k observations on more than 120 variables. We don't need them all.
#We therefore filter the database to make it fit our needs, erasing over a 100 variables.
#We only want to look at successfull terror attacks and include basic data on time, location and target.
GTD <- subset(rawGTD, select = c(eventid, iyear, imonth, iday, country, country_txt, region, provstate, region_txt, city, attacktype1, targtype1, targsubtype1,
weaptype1, weapsubtype1, propextent, nkill, nwound),
iyear >= 1970 & success == 1, na.strings = c("", " "))
rm(rawGTD)
#Next we order the GTD)
GTD <- GTD[order (GTD$country_txt, GTD$iyear, GTD$imonth, GTD$iday, GTD$city), ]
############################################
#We introduce our first scale: "Targets Urbanity Potential Scale (TUPscale)"
GTD["TUPscale"] <- GTD$targsubtype1
GTD$TUPscale <- recode(GTD$TUPscale, "40:42 = 9; 9 = 0; 27:35 = 0; 37:39 = 0; 65 = 0; 72 = 0; 1 = 2; 4:5 = 2; 10 = 2;
12 = 2; 53:56 = 2; 58:59 = 2; 61:62 = 2; 82 = 2; 95:96 = 2;6 = 9; 13 = 9; 104:108 = 9;
51:52 = 9; 57 = 9; 60 = 9; 63:64 = 9; 73 = 9; 80:81 = 9; 88:92 = 9; 98 = 9; 2 = 7; 3 = 7;
7:8 = 7; 44 = 7; 48:50 = 7; 67:71 = 7; 74:79 = 7; 83:87 = 7; 97 = 7; 99 = 7; 14:26 = 9;
100:103 = 9; 111 = 9; 109 = 9; 110 = 9; 36 = 9; 43 = 9; 45:47 = 9; 66 = 9; 93:94 = 9;
11 = 9", as.numeric.result=TRUE)
# 0= Rural & Military; 2= Government & Police; 3= Potentilly Urban Workplace; #7= Potentilly Urban Infrastructure;
# 9= Potentilly Expression of Urban Core Life
############################################
# We introduce our second scale: "Extent of Property Damage (PROPscale)" and write it back into the GTD
GTD["PROPscale"] <- GTD$propextent
GTD$PROPscale <- as.numeric(GTD$PROPscale)
#Bring the values to the $ values coded in the originally coded categories.
GTD$PROPscale <- recode(GTD$PROPscale, "1=1000000000; 2=1000000; 3=1000; 4=0; NA=NA")
############################################
# We introduce our third scale: "Extent of Human Damage (HUMscale)" which adds wounded and killed /and write it back into the GTD
GTD["HUMscale"] <- GTD$nkill+GTD$nwound
GTD$HUMscale <- as.numeric(GTD$HUMscale)
# run our cleaning code for bringing the GDT country code to World Bank levels
source('SmallScripts/CountryCleaning.R')
# download Wold Bank counrty level data and merge over country and year
source('WDIData.R')
